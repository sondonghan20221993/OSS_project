import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader
import os

# ---------------------
# 1. ë°ì´í„°ì…‹ & ì „ì²˜ë¦¬
# ---------------------
data_dir = "/kaggle/input/deepfake-database/deepfake_database"
batch_size = 32

transform = {
    "train": transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ]),
    "validation": transforms.Compose([   # ğŸ”‘ validation ì¶”ê°€
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ]),
    "test": transforms.Compose([         # ğŸ”‘ test ì¶”ê°€
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ])
}

# ğŸ“Œ í´ë” ê²½ë¡œ ê°ê° ì§€ì •
train_dataset = datasets.ImageFolder(os.path.join(data_dir, "train"), transform["train"])
val_dataset   = datasets.ImageFolder(os.path.join(data_dir, "validation"), transform["validation"])
test_dataset  = datasets.ImageFolder(os.path.join(data_dir, "test"), transform["test"])

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)
val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)
test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)

num_classes = len(train_dataset.classes)  # ë¼ë²¨ ê°œìˆ˜ ìë™ ì¶”ì¶œ

# ---------------------
# 2. ëª¨ë¸ ì •ì˜
# ---------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"âœ… Using device: {device}")

model = models.efficientnet_b0(weights="IMAGENET1K_V1")
model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)
model = model.to(device)

# ---------------------
# 3. Loss & Optimizer
# ---------------------
criterion = nn.CrossEntropyLoss()
optimizer = optim.AdamW(model.parameters(), lr=1e-4)

# ---------------------
# 4. í•™ìŠµ ë£¨í”„
# ---------------------
best_acc = 0.0
num_epochs = 10
save_path = "best_model.pth"

#ì§€ëŠ¥í˜• ë¦¬ìŠ¤íŠ¸ë¡œ ë¯¸ë¦¬ í• ë‹¹
train_loss_list = [None for _ in range(num_epochs)]
train_acc_list = [None for _ in range(num_epochs)]
val_loss_list = [None for _ in range(num_epochs)]
val_acc_list = [None for _ in range(num_epochs)] 

for epoch in range(num_epochs):
    print(f"\nEpoch [{epoch+1}/{num_epochs}]")

    # ---- Training ----
    model.train()
    running_loss, correct, total = 0.0, 0, 0
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * images.size(0)
        _, preds = outputs.max(1)
        correct += preds.eq(labels).sum().item()
        total += labels.size(0)

    train_loss = running_loss / total
    train_acc = correct / total

    # ---- Validation ----
    model.eval()
    val_loss, correct, total = 0.0, 0, 0
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)

            val_loss += loss.item() * images.size(0)
            _, preds = outputs.max(1)
            correct += preds.eq(labels).sum().item()
            total += labels.size(0)

    val_loss /= total
    val_acc = correct / total

    print(f"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}")
    print(f"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}")
    #í•´ì•¼í• ê²ƒ (ê²°ê³¼ì‹œê°í™”ë¥¼ ìœ„í•œ ê°’ ì €ì¥)----------------------------------------
    """
    í•´ë‹¹ ì—í¬í¬(ë°˜ë³µíšŸìˆ˜ì—)
    train_loss, val  #í•™ìŠµ ì†ì‹¤, ì •í™•ë„
    val_loss, val #í‰ê°€ ì†ì‹¤, ì •í™•ë„
    ì´ ì„ì‹œë³€ìˆ˜ë¡œ ì €ì¥ë˜ì–´ìˆë‹¤.
    ì´ê²ƒì„ train_loss_list ..ìœ¼ë¡œ ë§Œë“¤ì–´ë†“ì€ ì €ì¥ê³µê°„ì— ë„£ì–´ë³´ì
    ex)
    train_loss_list[num_epochs] = train loss #ì´ë ‡ê²Œí•˜ë©´ í•´ë‹¹ ë°˜ë³µíšŸìˆ˜ì˜ ê°’ì„ ë¦¬ìŠ¤íŠ¸ì— ë„£ëŠ”ë‹¤.
    
    """
    # ---- Save Best Model ----
    if val_acc > best_acc:
        best_acc = val_acc
        torch.save(model.state_dict(), save_path)
        print(f"âœ… ëª¨ë¸ ì €ì¥ë¨: {save_path}")
#í•´ì•¼í• ê²ƒ (ê²°ê³¼ì‹œê°í™”)----------------------------------------
"""
matplotlibí•¨ìˆ˜ë¥¼ ì´ìš©í•´ì„œ 
train_loss_lsit, train_acc_list, val_loss_lsit, val_acc_lsit

fig = plt.figure()
plt.plot(list([n for n in range(1, num_epochs+1)]), list(value for value in train_loss_list),marker='o', linestyle='-', label="train_loss") 
plt.legend()
plt.show()
#n for n in range(1, num_epochs+1)ë¡œ ë°˜ë³µíšŸì‰¬ xì¶•ìœ¼ë¡œ ì§€ì •
#train_loss_listê°’ì„ ë°˜ë³µë¬¸ìœ¼ë¡œ êº¼ëƒ„

ì´ëŸ¬í•œ í˜•ì‹ìœ¼ë¡œ train_acc_list, valëª¨ë‘ plotì„ ì´ìš©í•´ì„œ ê·¸ë¦¬ì


"""
print(f"\nğŸ¯ í•™ìŠµ ì™„ë£Œ! ìµœê³  ì •í™•ë„: {best_acc:.4f}")
